"""
Module eclat_algo.py - Thu·∫≠t to√°n Eclat cho Khai ph√° Itemsets Ph·ªï bi·∫øn

Thu·∫≠t to√°n: ECLAT (Equivalence Class Clustering and bottom-up Lattice Traversal)
T√°c gi·∫£ g·ªëc: Mohammed J. Zaki (1997)

T√†i li·ªáu tham kh·∫£o:
- Zaki, M.J. (2000). "Scalable Algorithms for Association Mining"
  IEEE Transactions on Knowledge and Data Engineering, 12(3), 372-390.

ƒê·∫∑c ƒëi·ªÉm ch√≠nh:
1. S·ª≠ d·ª•ng Vertical Data Format (ƒê·ªãnh d·∫°ng d·ªØ li·ªáu d·ªçc)
   - M·ªói item ƒë∆∞·ª£c l∆∞u k√®m danh s√°ch TID (Transaction IDs) ch·ª©a item ƒë√≥
   - VD: Item "News" -> TID-Set = {0, 2, 5, 8, 12, ...}

2. S·ª≠ d·ª•ng ph√©p giao TID-Sets ƒë·ªÉ t√≠nh Support
   - Support(A ‚à™ B) = |TID(A) ‚à© TID(B)| / N
   - Nhanh h∆°n Apriori do kh√¥ng c·∫ßn qu√©t l·∫°i database nhi·ªÅu l·∫ßn

3. Duy·ªát theo Depth-First Search (DFS)
   - Ti·∫øt ki·ªám b·ªô nh·ªõ h∆°n Breadth-First Search (BFS)
   - Ph√π h·ª£p cho mining t·∫≠p ph·ªï bi·∫øn c√≥ nhi·ªÅu items
"""


class Eclat:
    """
    L·ªõp tri·ªÉn khai thu·∫≠t to√°n Eclat ƒë·ªÉ t√¨m t·∫≠p m·ª•c ph·ªï bi·∫øn (Frequent Itemsets).
    
    Thu·∫≠t to√°n ho·∫°t ƒë·ªông theo 4 b∆∞·ªõc ch√≠nh:
    1. Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu ngang -> d·ªçc (TID-Set format)
    2. L·ªçc c√°c item ƒë∆°n l·∫ª kh√¥ng ƒë·∫°t ng∆∞·ª°ng support
    3. ƒê·ªá quy k·∫øt h·ª£p c√°c item v√† t√≠nh giao TID-Sets
    4. L∆∞u c√°c itemsets c√≥ support >= min_support
    
    Attributes:
        min_support (float): Ng∆∞·ª°ng support t·ªëi thi·ªÉu (0.0-1.0)
        min_items (int): S·ªë items t·ªëi thi·ªÉu trong 1 itemset (th∆∞·ªùng l√† 1 ho·∫∑c 2)
        frequent_itemsets (list): K·∫øt qu·∫£ - danh s√°ch (itemset, support_count)
    
    Example:
        >>> eclat = Eclat(min_support=0.02, min_items=2)
        >>> itemsets = eclat.fit(transactions)
        >>> for items, count in itemsets[:5]:
        ...     print(f"{items}: {count}")
    """
    
    def __init__(self, min_support=0.01, min_items=1):
        """
        Kh·ªüi t·∫°o thu·∫≠t to√°n Eclat.
        
        Args:
            min_support (float): Ng∆∞·ª°ng h·ªó tr·ª£ t·ªëi thi·ªÉu, ph·∫°m vi [0.0, 1.0]
                - 0.01 = 1%: Item ph·∫£i xu·∫•t hi·ªán trong √≠t nh·∫•t 1% s·ªë giao d·ªãch
                - 0.02 = 2%: Item ph·∫£i xu·∫•t hi·ªán trong √≠t nh·∫•t 2% s·ªë giao d·ªãch
                
            min_items (int): S·ªë l∆∞·ª£ng item t·ªëi thi·ªÉu trong m·ªôt itemset
                - 1: Bao g·ªìm c·∫£ ƒë∆°n l·∫ª (c·∫ßn thi·∫øt ƒë·ªÉ t√≠nh Lift)
                - 2: Ch·ªâ l·∫•y c√°c c·∫∑p item tr·ªü l√™n (d√πng cho sinh lu·∫≠t)
        
        Raises:
            ValueError: N·∫øu min_support kh√¥ng n·∫±m trong [0, 1]
        """
        if not 0 <= min_support <= 1:
            raise ValueError("min_support ph·∫£i n·∫±m trong kho·∫£ng [0, 1]")
        
        self.min_support = min_support
        self.min_items = min_items
        self.frequent_itemsets = []  # N∆°i l∆∞u k·∫øt qu·∫£ cu·ªëi c√πng
        self._total_transactions = 0  # L∆∞u ƒë·ªÉ t√≠nh support %

    def fit(self, dataset):
        """
        Ch·∫°y thu·∫≠t to√°n Eclat tr√™n b·ªô d·ªØ li·ªáu.
        
        Quy tr√¨nh:
        1. T√≠nh min_support_count = total_transactions √ó min_support
        2. Chuy·ªÉn ƒë·ªïi sang Vertical Data Format (TID-Sets)
        3. L·ªçc c√°c item kh√¥ng ƒë·∫°t ng∆∞·ª°ng
        4. ƒê·ªá quy t√¨m c√°c itemsets ph·ªï bi·∫øn
        
        Args:
            dataset (list of sets): D·ªØ li·ªáu ƒë·∫ßu v√†o t·ª´ data_loader.
                M·ªói ph·∫ßn t·ª≠ l√† 1 set c√°c items (t√™n chuy√™n m·ª•c).
                VD: [{'News', 'Tech'}, {'Frontpage', 'News'}, ...]
        
        Returns:
            list: Danh s√°ch c√°c itemsets ph·ªï bi·∫øn d·∫°ng (itemset, support_count)
                VD: [(['News', 'Tech'], 150), (['News'], 500), ...]
        
        Time Complexity: O(n √ó m √ó k) v·ªõi n=s·ªë giao d·ªãch, m=s·ªë items, k=ƒë·ªô s√¢u
        Space Complexity: O(n √ó m) cho TID-Sets
        """
        # Reset k·∫øt qu·∫£ t·ª´ l·∫ßn ch·∫°y tr∆∞·ªõc (n·∫øu c√≥)
        self.frequent_itemsets = []
        
        # 1. T√≠nh ng∆∞·ª°ng support tuy·ªát ƒë·ªëi (s·ªë l∆∞·ª£ng giao d·ªãch)
        self._total_transactions = len(dataset)
        min_support_count = self._total_transactions * self.min_support
        
        print(f"T·ªïng s·ªë phi√™n: {self._total_transactions:,}")
        print(f"Ng∆∞·ª°ng h·ªó tr·ª£: {min_support_count:.0f} ({self.min_support*100}%)")

        # 2. CHUY·ªÇN ƒê·ªîI D·ªÆ LI·ªÜU NGANG -> D·ªåC (Vertical Data Format)
        # D·∫°ng: { 'Item_A': {tid0, tid1, tid5}, 'Item_B': {tid2, tid3}, ... }
        # tid = Transaction ID (index c·ªßa giao d·ªãch trong dataset)
        tid_dict = {}
        
        for tid, transaction in enumerate(dataset):
            for item in transaction:
                if item not in tid_dict:
                    tid_dict[item] = set()
                tid_dict[item].add(tid)
        
        # 3. L·ªåC S·ªöM: Lo·∫°i b·ªè c√°c item ƒë∆°n l·∫ª kh√¥ng ƒë·ªß support (Pruning)
        # Theo nguy√™n l√Ω Apriori: N·∫øu item ƒë∆°n l·∫ª kh√¥ng ph·ªï bi·∫øn,
        # th√¨ m·ªçi t·∫≠p ch·ª©a item ƒë√≥ c≈©ng kh√¥ng ph·ªï bi·∫øn
        tid_dict = {
            item: tids 
            for item, tids in tid_dict.items() 
            if len(tids) >= min_support_count
        }
        
        print(f"S·ªë items ph·ªï bi·∫øn: {len(tid_dict)}")
        
        # 4. S·∫Øp x·∫øp theo ƒë·ªô ph·ªï bi·∫øn gi·∫£m d·∫ßn (T·ªëi ∆∞u: Pruning hi·ªáu qu·∫£ h∆°n)
        # Items ph·ªï bi·∫øn nh·∫•t x√©t tr∆∞·ªõc gi√∫p c·∫Øt t·ªâa nh√°nh nhanh h∆°n
        sorted_items = sorted(
            tid_dict.items(), 
            key=lambda x: len(x[1]), 
            reverse=True
        )
        
        # 5. B·∫ÆT ƒê·∫¶U ƒê·ªÜ QUY (Depth-First Search)
        print(f"ƒêang ch·∫°y thu·∫≠t to√°n Eclat...")
        
        self._eclat_recursive(
            prefix=[], 
            tid_subset=sorted_items, 
            min_support_count=min_support_count
        )
        
        print(f"T√¨m th·∫•y {len(self.frequent_itemsets)} t·∫≠p m·ª•c ph·ªï bi·∫øn.")
        return self.frequent_itemsets

    def _eclat_recursive(self, prefix, tid_subset, min_support_count):
        """
        H√†m ƒë·ªá quy c·ªët l√µi c·ªßa thu·∫≠t to√°n Eclat (Depth-First Search).
        
        Thu·∫≠t to√°n:
        - V·ªõi m·ªói item trong tid_subset, t·∫°o itemset m·ªõi = prefix + [item]
        - T√≠nh support = |TID-Set c·ªßa itemset m·ªõi|
        - N·∫øu ƒë·ªß support: L∆∞u v√†o k·∫øt qu·∫£ v√† ti·∫øp t·ª•c m·ªü r·ªông
        - D·ª´ng khi kh√¥ng c√≤n item n√†o c√≥ th·ªÉ k·∫øt h·ª£p
        
        Args:
            prefix (list): Itemset hi·ªán t·∫°i ƒëang x√©t
                VD: [] -> ['News'] -> ['News', 'Tech']
                
            tid_subset (list): Danh s√°ch c√°c (item, TID-Set) c√≤n l·∫°i ƒë·ªÉ x√©t
                ƒê∆∞·ª£c s·∫Øp x·∫øp theo ƒë·ªô ph·ªï bi·∫øn gi·∫£m d·∫ßn
                
            min_support_count (float): Ng∆∞·ª°ng support tuy·ªát ƒë·ªëi ƒë·ªÉ c·∫Øt t·ªâa
        """
        while tid_subset:
            # L·∫•y item ƒë·∫ßu ti√™n ra kh·ªèi danh s√°ch x√©t
            item, tids = tid_subset.pop(0)
            
            # T·∫°o itemset m·ªõi b·∫±ng c√°ch th√™m item v√†o prefix
            # VD: prefix=['News'], item='Tech' -> new_itemset=['News', 'Tech']
            new_itemset = prefix + [item]
            
            # Support = S·ªë giao d·ªãch ch·ª©a itemset n√†y
            support_count = len(tids)
            
            # L∆∞u itemset n·∫øu c√≥ ƒë·ªß s·ªë items theo y√™u c·∫ßu
            # (min_items=1: l·∫•y c·∫£ ƒë∆°n l·∫ª, min_items=2: ch·ªâ l·∫•y c·∫∑p tr·ªü l√™n)
            if len(new_itemset) >= self.min_items:
                self.frequent_itemsets.append((new_itemset, support_count))
            
            # --- B∆Ø·ªöC THEN CH·ªêT: T√çNH GIAO TID-SETS ---
            # T√¨m c√°c item c√≥ th·ªÉ k·∫øt h·ª£p ti·∫øp v·ªõi new_itemset
            new_tid_subset = []
            
            for other_item, other_tids in tid_subset:
                # Ph√©p giao: Ch·ªâ gi·ªØ l·∫°i TID xu·∫•t hi·ªán ·ªü C·∫¢ HAI items
                # Support(A ‚à™ B) = |TID(A) ‚à© TID(B)|
                intersect_tids = tids & other_tids  # Ph√©p to√°n set intersection
                
                # Ch·ªâ gi·ªØ l·∫°i n·∫øu t·∫≠p giao v·∫´n ƒë·ªß l·ªõn (Pruning)
                if len(intersect_tids) >= min_support_count:
                    new_tid_subset.append((other_item, intersect_tids))
            
            # ƒê·ªá quy ƒë·ªÉ ƒëi s√¢u h∆°n (Depth-First)
            if new_tid_subset:
                self._eclat_recursive(
                    new_itemset, 
                    new_tid_subset, 
                    min_support_count
                )

    def get_support(self, itemset):
        """
        T√≠nh support c·ªßa m·ªôt itemset c·ª• th·ªÉ.
        
        Args:
            itemset (list): Itemset c·∫ßn t√≠nh support
            
        Returns:
            float: Support d·∫°ng t·ª∑ l·ªá (0.0 - 1.0), ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
        """
        for items, count in self.frequent_itemsets:
            if sorted(items) == sorted(itemset):
                return count / self._total_transactions if self._total_transactions > 0 else 0
        return None


# ============================================================
# KH·ªêI TEST (Ch·∫°y th·ª≠ file n√†y ƒë·ªôc l·∫≠p)
# ============================================================
if __name__ == "__main__":
    # D·ªØ li·ªáu gi·∫£ l·∫≠p ƒë·ªÉ test logic thu·∫≠t to√°n
    # C√°c giao d·ªãch m·∫´u v·ªõi 5 items: A, B, C, D, E
    dummy_data = [
        {'A', 'C', 'D'},
        {'B', 'C', 'E'},
        {'A', 'B', 'C', 'E'},
        {'B', 'E'},
        {'A', 'B', 'C', 'E'},
    ]
    
    print("=" * 50)
    print("TEST THU·∫¨T TO√ÅN ECLAT V·ªöI D·ªÆ LI·ªÜU GI·∫¢ L·∫¨P")
    print("=" * 50)
    
    # Min support 40% (xu·∫•t hi·ªán trong √≠t nh·∫•t 2/5 giao d·ªãch)
    model = Eclat(min_support=0.4, min_items=1)
    results = model.fit(dummy_data)
    
    print("\nüìä K·∫øt qu·∫£ (Itemset : Support Count : Support %):")
    print("-" * 50)
    for itemset, count in sorted(results, key=lambda x: len(x[0])):
        support_pct = count / len(dummy_data) * 100
        print(f"  {itemset} : {count} : {support_pct:.1f}%")
    
    print("\n‚úÖ Test ho√†n t·∫•t!")
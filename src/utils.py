"""
Module utils.py - Sinh luáº­t káº¿t há»£p vÃ  hiá»ƒn thá»‹ gá»£i Ã½ ná»™i dung

CÃ¡c chá»‰ sá»‘ Ä‘Æ°á»£c tÃ­nh theo chuáº©n lÃ½ thuyáº¿t Association Rule Mining:

1. Support(A â†’ B) = P(A âˆ© B) = |T(A âˆ© B)| / |T|
   - Táº§n suáº¥t xuáº¥t hiá»‡n Ä‘á»“ng thá»i cá»§a A vÃ  B trong toÃ n bá»™ giao dá»‹ch
   
2. Confidence(A â†’ B) = P(B|A) = Support(A âˆª B) / Support(A)
   - XÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n: Náº¿u ngÆ°á»i dÃ¹ng xem A, kháº£ nÄƒng xem B lÃ  bao nhiÃªu?
   
3. Lift(A â†’ B) = Support(A âˆª B) / (Support(A) Ã— Support(B))
   - Äá»™ tÆ°Æ¡ng quan: Lift > 1 nghÄ©a lÃ  A vÃ  B cÃ³ tÆ°Æ¡ng quan tÃ­ch cá»±c
   - Lift = 1: A vÃ  B Ä‘á»™c láº­p thá»‘ng kÃª
   - Lift < 1: A vÃ  B cÃ³ tÆ°Æ¡ng quan Ã¢m (hiáº¿m khi xuáº¥t hiá»‡n cÃ¹ng nhau)

TÃ i liá»‡u tham kháº£o:
- Agrawal, R., Imielinski, T., & Swami, A. (1993). 
  "Mining association rules between sets of items in large databases"
  ACM SIGMOD Conference
"""


def generate_recommendation_rules(frequent_itemsets, total_transactions, min_confidence=0.5):
    """
    Sinh ra cÃ¡c luáº­t gá»£i Ã½ ná»™i dung tá»« táº­p má»¥c phá»• biáº¿n.
    
    Vá»›i má»—i táº­p {A, B}, sinh 2 luáº­t:
    - A â†’ B: Náº¿u ngÆ°á»i dÃ¹ng xem A, gá»£i Ã½ B
    - B â†’ A: Náº¿u ngÆ°á»i dÃ¹ng xem B, gá»£i Ã½ A
    
    Args:
        frequent_itemsets (list): Káº¿t quáº£ tá»« thuáº­t toÃ¡n Eclat.
            Dáº¡ng: [(['News', 'Tech'], 500), (['News'], 1000), ...]
            
        total_transactions (int): Tá»•ng sá»‘ phiÃªn giao dá»‹ch (N).
            Cáº§n thiáº¿t Ä‘á»ƒ tÃ­nh Support dáº¡ng pháº§n trÄƒm.
            
        min_confidence (float): NgÆ°á»¡ng tin cáº­y tá»‘i thiá»ƒu [0.0, 1.0]
            - 0.4 = 40%: Ãt nháº¥t 40% ngÆ°á»i xem A sáº½ xem B
            - 0.5 = 50%: Ãt nháº¥t 50% ngÆ°á»i xem A sáº½ xem B
    
    Returns:
        rules (list of dict): Danh sÃ¡ch cÃ¡c luáº­t gá»£i Ã½, má»—i luáº­t gá»“m:
            - antecedent: Váº¿ trÃ¡i (Ä‘iá»u kiá»‡n) - list
            - consequent: Váº¿ pháº£i (káº¿t luáº­n) - list
            - support: Support(A âˆª B) - float [0, 1]
            - confidence: P(B|A) - float [0, 1]
            - lift: Äá»™ tÆ°Æ¡ng quan - float (> 1 lÃ  tá»‘t)
    
    Example:
        >>> rules = generate_recommendation_rules(itemsets, 50000, 0.4)
        >>> for r in rules[:3]:
        ...     print(f"{r['antecedent']} â†’ {r['consequent']}: Lift={r['lift']:.2f}")
    """
    rules = []
    
    # 1. Chuyá»ƒn list thÃ nh dictionary Ä‘á»ƒ tra cá»©u nhanh Support Count
    # Key: tuple Ä‘Ã£ sort Ä‘á»ƒ Ä‘áº£m báº£o ('News', 'Tech') == ('Tech', 'News')
    support_lookup = {}
    for itemset, support_count in frequent_itemsets:
        key = tuple(sorted(itemset))
        support_lookup[key] = support_count

    print(f"Sinh luáº­t tá»« {len(frequent_itemsets)} táº­p phá»• biáº¿n...")

    import itertools

    # 2. Duyá»‡t qua cÃ¡c táº­p phá»• biáº¿n cÃ³ tá»« 2 items trá»Ÿ lÃªn
    for itemset, support_count_AB in frequent_itemsets:
        if len(itemset) < 2:
            continue
        
        # Support(X âˆª Y) = Support cá»§a cáº£ itemset
        support_AB = support_count_AB / total_transactions
        
        # Sinh táº¥t cáº£ cÃ¡c táº­p con khÃ¡c rá»—ng cá»§a itemset lÃ m váº¿ trÃ¡i (X)
        # VD: itemset {A, B, C} -> X cÃ³ thá»ƒ lÃ  {A}, {B}, {C}, {A,B}, {A,C}, {B,C}
        all_antecedents = []
        for r in range(1, len(itemset)):
            all_antecedents.extend(itertools.combinations(itemset, r))
            
        for antecedent_tuple in all_antecedents:
            antecedent = list(antecedent_tuple)
            antecedent_key = tuple(sorted(antecedent))
            
            # Váº¿ pháº£i (Y) = Itemset - X
            consequent = [item for item in itemset if item not in antecedent]
            consequent_key = tuple(sorted(consequent))
            
            # Láº¥y Support Count cá»§a váº¿ trÃ¡i (X)
            support_count_A = support_lookup.get(antecedent_key)
            
            if support_count_A is None:
                continue
            
            # TÃ­nh cÃ¡c chá»‰ sá»‘
            support_A = support_count_A / total_transactions
            
            # Confidence(X -> Y) = Support(XY) / Support(X)
            confidence = support_AB / support_A if support_A > 0 else 0
            
            # Lift = Confidence / Support(Y)
            # Cáº§n support_B Ä‘á»ƒ tÃ­nh Lift
            support_count_B = support_lookup.get(consequent_key)
            if support_count_B:
                support_B = support_count_B / total_transactions
                lift = confidence / support_B if support_B > 0 else 0
            else:
                lift = 0 # KhÃ´ng tÃ­nh Ä‘Æ°á»£c náº¿u khÃ´ng cÃ³ thÃ´ng tin váº¿ pháº£i
            
            # Chá»‰ lÆ°u luáº­t náº¿u Ä‘áº¡t ngÆ°á»¡ng Confidence
            if confidence >= min_confidence:
                rules.append({
                    'antecedent': antecedent,
                    'consequent': consequent,
                    'support': support_AB,
                    'confidence': confidence,
                    'lift': lift
                })

    # Sáº¯p xáº¿p: Æ¯u tiÃªn Lift cao (tÆ°Æ¡ng quan máº¡nh), sau Ä‘Ã³ lÃ  Confidence
    rules.sort(key=lambda x: (x['lift'], x['confidence']), reverse=True)
    
    print(f"ÄÃ£ sinh {len(rules)} luáº­t thá»a mÃ£n Confidence >= {min_confidence*100:.0f}%")
    
    return rules


def print_recommendations(rules, top_n=10):
    """
    In danh sÃ¡ch gá»£i Ã½ ná»™i dung ra mÃ n hÃ¬nh vá»›i Ä‘á»‹nh dáº¡ng báº£ng.
    """
    if not rules:
        print("\nKhÃ´ng cÃ³ luáº­t gá»£i Ã½ nÃ o.")
        return
    
    actual_count = min(top_n, len(rules))
    
    print(f"\n{'='*60}")
    print(f"   TOP {actual_count} LUáº¬T Gá»¢I Ã Ná»˜I DUNG")
    print(f"{'='*60}")
    
    # TÃ­nh toÃ¡n Ä‘á»™ rá»™ng cá»™t Ä‘á»™ng dá»±a trÃªn dá»¯ liá»‡u
    # Máº·c Ä‘á»‹nh tá»‘i thiá»ƒu lÃ  Ä‘á»™ dÃ i cá»§a Header (Náº¾U XEM = 7, Gá»¢I Ã = 5)
    max_len_ant = 7
    max_len_cons = 5
    
    # Chá»‰ xÃ©t trong top_n luáº­t sáº½ in Ä‘á»ƒ tá»‘i Æ°u
    rules_to_print = rules[:top_n]
    
    for rule in rules_to_print:
        ant_len = len(", ".join(rule['antecedent']))
        cons_len = len(", ".join(rule['consequent']))
        if ant_len > max_len_ant: max_len_ant = ant_len
        if cons_len > max_len_cons: max_len_cons = cons_len
        
    # ThÃªm padding cho thoÃ¡ng
    w_ant = max_len_ant + 2
    w_cons = max_len_cons + 2
    
    # Header báº£ng
    # Sá»­ dá»¥ng biáº¿n Ä‘á»™ rá»™ng Ä‘á»™ng trong f-string
    print(f"\n{'STT':<4} | {f'Náº¾U XEM':<{w_ant}} | {f'Gá»¢I Ã':<{w_cons}} | {'SUP':<7} | {'CONF':<7} | {'LIFT':<5}")
    print("-" * (4 + 3 + w_ant + 3 + w_cons + 3 + 7 + 3 + 7 + 3 + 5))
    
    for i, rule in enumerate(rules_to_print, 1):
        antecedent_str = ", ".join(rule['antecedent'])
        consequent_str = ", ".join(rule['consequent'])
        support_pct = f"{rule['support']*100:.2f}%"
        conf_pct = f"{rule['confidence']*100:.1f}%"
        lift_val = f"{rule['lift']:.2f}"
        
        print(f"{i:<4} | {antecedent_str:<{w_ant}} | {consequent_str:<{w_cons}} | {support_pct:<7} | {conf_pct:<7} | {lift_val:<5}")
    
    print("-" * (4 + 3 + w_ant + 3 + w_cons + 3 + 7 + 3 + 7 + 3 + 5))
    
    # Luáº­t tá»‘t nháº¥t
    if rules:
        top = rules[0]
        # Tá»•ng quÃ¡t hÃ³a: Ná»‘i chuá»—i táº¥t cáº£ cÃ¡c items, khÃ´ng chá»‰ láº¥y item Ä‘áº§u tiÃªn
        ant = ", ".join(top['antecedent'])
        cons = ", ".join(top['consequent'])
        
        print(f"\nGá»£i Ã½ tá»‘t nháº¥t: NgÆ°á»i xem [{ant}] -> gá»£i Ã½ [{cons}]")
        print(f"Lift = {top['lift']:.2f} (cao hÆ¡n ngáº«u nhiÃªn {(top['lift']-1)*100:.0f}%)\n")



def export_rules_to_csv(rules, filepath):
    """
    Xuáº¥t danh sÃ¡ch luáº­t ra file CSV Ä‘á»ƒ phÃ¢n tÃ­ch thÃªm.
    
    Args:
        rules (list): Danh sÃ¡ch luáº­t tá»« generate_recommendation_rules()
        filepath (str): ÄÆ°á»ng dáº«n file CSV Ä‘áº§u ra
    """
    import csv
    
    with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(['Antecedent', 'Consequent', 'Support', 'Confidence', 'Lift'])
        
        for rule in rules:
            writer.writerow([
                ', '.join(rule['antecedent']),
                ', '.join(rule['consequent']),
                f"{rule['support']:.4f}",
                f"{rule['confidence']:.4f}",
                f"{rule['lift']:.4f}"
            ])
    
    print(f"âœ… ÄÃ£ xuáº¥t {len(rules)} luáº­t ra file: {filepath}")


# ============================================================
# KHá»I TEST (Cháº¡y thá»­ file nÃ y Ä‘á»™c láº­p)
# ============================================================
if __name__ == "__main__":
    # Dá»¯ liá»‡u máº«u Ä‘á»ƒ test cÃ´ng thá»©c
    # Giáº£ sá»­: 1000 giao dá»‹ch tá»•ng cá»™ng
    test_data = [
        (['News'], 500),          # Support(News) = 50%
        (['Tech'], 300),          # Support(Tech) = 30%
        (['Sports'], 200),        # Support(Sports) = 20%
        (['News', 'Tech'], 150),  # Support(News, Tech) = 15%
        (['News', 'Sports'], 80), # Support(News, Sports) = 8%
    ]
    
    print("=" * 60)
    print("TEST MODULE UTILS - TÃ­nh toÃ¡n Association Rules")
    print("=" * 60)
    
    rules = generate_recommendation_rules(
        test_data, 
        total_transactions=1000, 
        min_confidence=0.2
    )
    
    print_recommendations(rules, top_n=10)
    
    # Kiá»ƒm tra cÃ´ng thá»©c thá»§ cÃ´ng
    print("\nğŸ“ KIá»‚M TRA CÃ”NG THá»¨C THá»¦ CÃ”NG:")
    print("-" * 60)
    print("Luáº­t: News â†’ Tech")
    print(f"   Support(News, Tech) = 150/1000 = 15%")
    print(f"   Confidence = 15% / 50% = 30%")
    print(f"   Lift = 15% / (50% Ã— 30%) = 15% / 15% = 1.0")
"""
Module utils.py - Sinh lu·∫≠t k·∫øt h·ª£p v√† hi·ªÉn th·ªã g·ª£i √Ω n·ªôi dung

C√°c ch·ªâ s·ªë ƒë∆∞·ª£c t√≠nh theo chu·∫©n l√Ω thuy·∫øt Association Rule Mining:

1. Support(A ‚Üí B) = P(A ‚à© B) = |T(A ‚à© B)| / |T|
   - T·∫ßn su·∫•t xu·∫•t hi·ªán ƒë·ªìng th·ªùi c·ªßa A v√† B trong to√†n b·ªô giao d·ªãch
   
2. Confidence(A ‚Üí B) = P(B|A) = Support(A ‚à™ B) / Support(A)
   - X√°c su·∫•t c√≥ ƒëi·ªÅu ki·ªán: N·∫øu ng∆∞·ªùi d√πng xem A, kh·∫£ nƒÉng xem B l√† bao nhi√™u?
   
3. Lift(A ‚Üí B) = Support(A ‚à™ B) / (Support(A) √ó Support(B))
   - ƒê·ªô t∆∞∆°ng quan: Lift > 1 nghƒ©a l√† A v√† B c√≥ t∆∞∆°ng quan t√≠ch c·ª±c
   - Lift = 1: A v√† B ƒë·ªôc l·∫≠p th·ªëng k√™
   - Lift < 1: A v√† B c√≥ t∆∞∆°ng quan √¢m (hi·∫øm khi xu·∫•t hi·ªán c√πng nhau)

T√†i li·ªáu tham kh·∫£o:
- Agrawal, R., Imielinski, T., & Swami, A. (1993). 
  "Mining association rules between sets of items in large databases"
  ACM SIGMOD Conference
"""


def generate_recommendation_rules(frequent_itemsets, total_transactions, min_confidence=0.5):
    """
    Sinh ra c√°c lu·∫≠t g·ª£i √Ω n·ªôi dung t·ª´ t·∫≠p m·ª•c ph·ªï bi·∫øn.
    
    V·ªõi m·ªói t·∫≠p {A, B}, sinh 2 lu·∫≠t:
    - A ‚Üí B: N·∫øu ng∆∞·ªùi d√πng xem A, g·ª£i √Ω B
    - B ‚Üí A: N·∫øu ng∆∞·ªùi d√πng xem B, g·ª£i √Ω A
    
    Args:
        frequent_itemsets (list): K·∫øt qu·∫£ t·ª´ thu·∫≠t to√°n Eclat.
            D·∫°ng: [(['News', 'Tech'], 500), (['News'], 1000), ...]
            
        total_transactions (int): T·ªïng s·ªë phi√™n giao d·ªãch (N).
            C·∫ßn thi·∫øt ƒë·ªÉ t√≠nh Support d·∫°ng ph·∫ßn trƒÉm.
            
        min_confidence (float): Ng∆∞·ª°ng tin c·∫≠y t·ªëi thi·ªÉu [0.0, 1.0]
            - 0.4 = 40%: √çt nh·∫•t 40% ng∆∞·ªùi xem A s·∫Ω xem B
            - 0.5 = 50%: √çt nh·∫•t 50% ng∆∞·ªùi xem A s·∫Ω xem B
    
    Returns:
        rules (list of dict): Danh s√°ch c√°c lu·∫≠t g·ª£i √Ω, m·ªói lu·∫≠t g·ªìm:
            - antecedent: V·∫ø tr√°i (ƒëi·ªÅu ki·ªán) - list
            - consequent: V·∫ø ph·∫£i (k·∫øt lu·∫≠n) - list
            - support: Support(A ‚à™ B) - float [0, 1]
            - confidence: P(B|A) - float [0, 1]
            - lift: ƒê·ªô t∆∞∆°ng quan - float (> 1 l√† t·ªët)
    
    Example:
        >>> rules = generate_recommendation_rules(itemsets, 50000, 0.4)
        >>> for r in rules[:3]:
        ...     print(f"{r['antecedent']} ‚Üí {r['consequent']}: Lift={r['lift']:.2f}")
    """
    rules = []
    
    # 1. Chuy·ªÉn list th√†nh dictionary ƒë·ªÉ tra c·ª©u nhanh Support Count
    # Key: tuple ƒë√£ sort ƒë·ªÉ ƒë·∫£m b·∫£o ('News', 'Tech') == ('Tech', 'News')
    support_lookup = {}
    for itemset, support_count in frequent_itemsets:
        key = tuple(sorted(itemset))
        support_lookup[key] = support_count

    print(f"Sinh lu·∫≠t t·ª´ {len(frequent_itemsets)} t·∫≠p ph·ªï bi·∫øn...")

    # 2. Duy·ªát qua c√°c t·∫≠p ph·ªï bi·∫øn c√≥ t·ª´ 2 items tr·ªü l√™n
    for itemset, support_count_AB in frequent_itemsets:
        if len(itemset) < 2:
            continue  # B·ªè qua t·∫≠p ƒë∆°n l·∫ª (kh√¥ng t·∫°o ƒë∆∞·ª£c lu·∫≠t A ‚Üí B)
        
        # Support(A ‚à™ B) = |T(A ‚à© B)| / N
        support_AB = support_count_AB / total_transactions
            
        # V·ªõi t·∫≠p {A, B}, t·∫°o c√°c lu·∫≠t:
        # - A ‚Üí B: Confidence = Support(A,B) / Support(A)
        # - B ‚Üí A: Confidence = Support(A,B) / Support(B)
        
        for antecedent_item in itemset:
            # V·∫ø tr√°i (Antecedent): Item ƒë∆∞·ª£c ch·ªçn l√†m ƒëi·ªÅu ki·ªán
            antecedent = [antecedent_item]
            antecedent_key = tuple(antecedent)
            
            # V·∫ø ph·∫£i (Consequent): C√°c items c√≤n l·∫°i
            consequent = [item for item in itemset if item != antecedent_item]
            consequent_key = tuple(sorted(consequent))
            
            # L·∫•y Support Count c·ªßa v·∫ø tr√°i (A) v√† v·∫ø ph·∫£i (B)
            support_count_A = support_lookup.get(antecedent_key)
            support_count_B = support_lookup.get(consequent_key)
            
            # Ki·ªÉm tra: C·∫ßn c√≥ support c·ªßa c·∫£ A v√† B ƒë·ªÉ t√≠nh Lift
            if support_count_A is None or support_count_B is None:
                continue
            
            # T√≠nh Support c·ªßa A v√† B ri√™ng l·∫ª
            support_A = support_count_A / total_transactions
            support_B = support_count_B / total_transactions
            
            # ============================================================
            # C√îNG TH·ª®C CH√çNH
            # ============================================================
            
            # Confidence(A ‚Üí B) = P(B|A) = Support(A ‚à™ B) / Support(A)
            confidence = support_AB / support_A if support_A > 0 else 0
            
            # Lift(A ‚Üí B) = Support(A ‚à™ B) / (Support(A) √ó Support(B))
            # C√¥ng th·ª©c t∆∞∆°ng ƒë∆∞∆°ng: Lift = Confidence / Support(B)
            # Interpretation:
            #   - Lift > 1: A v√† B xu·∫•t hi·ªán c√πng nhau nhi·ªÅu h∆°n ng·∫´u nhi√™n (T√≠ch c·ª±c)
            #   - Lift = 1: A v√† B ƒë·ªôc l·∫≠p th·ªëng k√™
            #   - Lift < 1: A v√† B √≠t xu·∫•t hi·ªán c√πng nhau (Ti√™u c·ª±c)
            expected_support = support_A * support_B
            lift = support_AB / expected_support if expected_support > 0 else 0
            
            # Ch·ªâ l∆∞u lu·∫≠t n·∫øu ƒë·∫°t ng∆∞·ª°ng Confidence
            if confidence >= min_confidence:
                rules.append({
                    'antecedent': antecedent,
                    'consequent': consequent,
                    'support': support_AB,
                    'confidence': confidence,
                    'lift': lift
                })

    # S·∫Øp x·∫øp: ∆Øu ti√™n Lift cao (t∆∞∆°ng quan m·∫°nh), sau ƒë√≥ l√† Confidence
    rules.sort(key=lambda x: (x['lift'], x['confidence']), reverse=True)
    
    print(f"ƒê√£ sinh {len(rules)} lu·∫≠t th·ªèa m√£n Confidence >= {min_confidence*100:.0f}%")
    
    return rules


def print_recommendations(rules, top_n=10):
    """
    In danh s√°ch g·ª£i √Ω n·ªôi dung ra m√†n h√¨nh v·ªõi ƒë·ªãnh d·∫°ng b·∫£ng.
    """
    if not rules:
        print("\nKh√¥ng c√≥ lu·∫≠t g·ª£i √Ω n√†o.")
        return
    
    actual_count = min(top_n, len(rules))
    
    print(f"\n{'='*60}")
    print(f"   TOP {actual_count} LU·∫¨T G·ª¢I √ù N·ªòI DUNG")
    print(f"{'='*60}")
    
    # Header b·∫£ng
    print(f"\n{'STT':<4} | {'N·∫æU XEM':<15} | {'G·ª¢I √ù':<15} | {'SUP':<7} | {'CONF':<7} | {'LIFT':<5}")
    print("-" * 60)
    
    for i, rule in enumerate(rules[:top_n], 1):
        antecedent_str = ", ".join(rule['antecedent'])
        consequent_str = ", ".join(rule['consequent'])
        support_pct = f"{rule['support']*100:.2f}%"
        conf_pct = f"{rule['confidence']*100:.1f}%"
        lift_val = f"{rule['lift']:.2f}"
        
        print(f"{i:<4} | {antecedent_str:<15} | {consequent_str:<15} | {support_pct:<7} | {conf_pct:<7} | {lift_val:<5}")
    
    print("-" * 60)
    
    # Lu·∫≠t t·ªët nh·∫•t
    if rules:
        top = rules[0]
        ant = top['antecedent'][0]
        cons = top['consequent'][0] if len(top['consequent']) == 1 else ", ".join(top['consequent'])
        print(f"\nG·ª£i √Ω t·ªët nh·∫•t: Ng∆∞·ªùi xem [{ant}] -> g·ª£i √Ω [{cons}]")
        print(f"Lift = {top['lift']:.2f} (cao h∆°n ng·∫´u nhi√™n {(top['lift']-1)*100:.0f}%)\n")



def export_rules_to_csv(rules, filepath):
    """
    Xu·∫•t danh s√°ch lu·∫≠t ra file CSV ƒë·ªÉ ph√¢n t√≠ch th√™m.
    
    Args:
        rules (list): Danh s√°ch lu·∫≠t t·ª´ generate_recommendation_rules()
        filepath (str): ƒê∆∞·ªùng d·∫´n file CSV ƒë·∫ßu ra
    """
    import csv
    
    with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(['Antecedent', 'Consequent', 'Support', 'Confidence', 'Lift'])
        
        for rule in rules:
            writer.writerow([
                ', '.join(rule['antecedent']),
                ', '.join(rule['consequent']),
                f"{rule['support']:.4f}",
                f"{rule['confidence']:.4f}",
                f"{rule['lift']:.4f}"
            ])
    
    print(f"‚úÖ ƒê√£ xu·∫•t {len(rules)} lu·∫≠t ra file: {filepath}")


# ============================================================
# KH·ªêI TEST (Ch·∫°y th·ª≠ file n√†y ƒë·ªôc l·∫≠p)
# ============================================================
if __name__ == "__main__":
    # D·ªØ li·ªáu m·∫´u ƒë·ªÉ test c√¥ng th·ª©c
    # Gi·∫£ s·ª≠: 1000 giao d·ªãch t·ªïng c·ªông
    test_data = [
        (['News'], 500),          # Support(News) = 50%
        (['Tech'], 300),          # Support(Tech) = 30%
        (['Sports'], 200),        # Support(Sports) = 20%
        (['News', 'Tech'], 150),  # Support(News, Tech) = 15%
        (['News', 'Sports'], 80), # Support(News, Sports) = 8%
    ]
    
    print("=" * 60)
    print("TEST MODULE UTILS - T√≠nh to√°n Association Rules")
    print("=" * 60)
    
    rules = generate_recommendation_rules(
        test_data, 
        total_transactions=1000, 
        min_confidence=0.2
    )
    
    print_recommendations(rules, top_n=10)
    
    # Ki·ªÉm tra c√¥ng th·ª©c th·ªß c√¥ng
    print("\nüìê KI·ªÇM TRA C√îNG TH·ª®C TH·ª¶ C√îNG:")
    print("-" * 60)
    print("Lu·∫≠t: News ‚Üí Tech")
    print(f"   Support(News, Tech) = 150/1000 = 15%")
    print(f"   Confidence = 15% / 50% = 30%")
    print(f"   Lift = 15% / (50% √ó 30%) = 15% / 15% = 1.0")